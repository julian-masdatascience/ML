{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxwzBku2pjLnCgVujDUSaK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julian-masdatascience/ML/blob/master/LinearClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gEkUu5-Jn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yflJthNF-LUX",
        "colab_type": "text"
      },
      "source": [
        "## Linear Classification\n",
        "### KNN classification\n",
        "In this exercise you'll explore a subset of the [Large Movie Review Datase](http://ai.stanford.edu/~amaas/data/sentiment/)t. The variables X_train, X_test, y_train, and y_test are already loaded into the environment. The X variables contain features based on the words in the movie reviews, and the y variables contain labels for whether the review sentiment is positive (+1) or negative (-1).\n",
        "\n",
        "This course touches on a lot of concepts you may have forgotten, so if you ever need a quick refresher, download the [Scikit-Learn Cheat Sheet](https://datacamp-community-prod.s3.amazonaws.com/5433fa18-9f43-44cc-b228-74672efcd116) and keep it handy!\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create a KNN model with default hyperparameters.\n",
        "Fit the model.\n",
        "Print out the prediction for the test example 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSoWaHz3AjtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create and fit the model\n",
        "knn = ____\n",
        "knn.____\n",
        "\n",
        "# Predict on the test features, print the results\n",
        "pred = knn.____[0]\n",
        "print(\"Prediction for test example 0:\", pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1IukGveAkTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create and fit the model\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the test features, print the results\n",
        "pred = knn.predict(X_test)[0]\n",
        "print(\"Prediction for test example 0:\", pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIvSofioCEss",
        "colab_type": "text"
      },
      "source": [
        "### Comparing models\n",
        "Compare k nearest neighbors classifiers with k=1 and k=5 on the handwritten digits data set, which is already loaded into the variables X_train, y_train, X_test, and y_test. You can set k with the n_neighbors parameter when creating the KNeighborsClassifier object, which is also already imported into the environment.\n",
        "\n",
        "Which model has a higher test accuracy? **5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O51qmgenC6jL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create and fit the model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the test features, print the results\n",
        "pred = knn.predict(X_test)[0]\n",
        "print(\"Prediction for test example 0:\", pred)\n",
        "print(knn.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6QdfnScDBnX",
        "colab_type": "text"
      },
      "source": [
        "### Overfitting\n",
        "Which of the following situations looks like an example of overfitting?\n",
        "\n",
        "Answer the question\n",
        "50 XP\n",
        "Possible Answers\n",
        "Training accuracy 50%, testing accuracy 50%.\n",
        "press\n",
        "1\n",
        "Training accuracy 95%, testing accuracy 95%.\n",
        "press\n",
        "2\n",
        "**Training accuracy 95%, testing accuracy 50%.**\n",
        "press\n",
        "3\n",
        "Training accuracy 50%, testing accuracy 95%.\n",
        "press\n",
        "Por que hay mejores resultados en el entrenamiento que e las pruebas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFgv7ri8DTL9",
        "colab_type": "text"
      },
      "source": [
        "### Running LogisticRegression and SVC\n",
        "In this exercise, you'll apply logistic regression and a support vector machine to classify images of handwritten digits.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Apply logistic regression and SVM (using SVC()) to the handwritten digits data set using the provided train/validation split.\n",
        "For each classifier, print out the training and validation accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev7hCVzNH0CA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "digits = datasets.load_digits()\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
        "\n",
        "# Apply logistic regression and print scores\n",
        "lr = LogisticRegression()  \n",
        "lr.____\n",
        "print(____)\n",
        "print(____)\n",
        "\n",
        "# Apply SVM and print scores\n",
        "svm = ____\n",
        "svm.____\n",
        "print(____)\n",
        "print(____)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGX750L_LD8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "f574f300-929a-42d6-9ee2-a0bc4fea79f6"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "digits = datasets.load_digits()\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC,SVC\n",
        "# Apply logistic regression and print scores\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "print(lr.score(X_train, y_train))\n",
        "print(lr.score(X_test, y_test))\n",
        "\n",
        "# Apply SVM and print scores\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "print(svm.score(X_train, y_train))\n",
        "print(svm.score(X_test, y_test))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.9666666666666667\n",
            "0.9962880475129918\n",
            "0.9933333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX6l0kplN1_2",
        "colab_type": "text"
      },
      "source": [
        "### Sentiment analysis for movie reviews\n",
        "In this exercise you'll explore the probabilities outputted by logistic regression on a subset of the Large Movie Review Dataset.\n",
        "\n",
        "The variables X and y are already loaded into the environment. X contains features based on the number of times words appear in the movie reviews, and y contains labels for whether the review sentiment is positive (+1) or negative (-1).\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Train a logistic regression model on the movie review data.\n",
        "Predict the probabilities of negative vs. positive for the two given reviews.\n",
        "Feel free to write your own reviews and get probabilities for those too!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faW_DhRCH1jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d8fd903-cafe-4035-fc86-5ed6ab844166"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile # para descomprimir archivos zip\n",
        "import urllib.request # para descargar de URL\n",
        "\n",
        "# descargar MovieLens dataset\n",
        "url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'  \n",
        "urllib.request.urlretrieve(url, 'm1-1m.zip')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('m1-1m.zip', <http.client.HTTPMessage at 0x7f1452c78da0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e65_ykQbO1Mz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d5ac23cf-da41-4018-b925-271db57117c2"
      },
      "source": [
        "with zipfile.ZipFile('m1-1m.zip', 'r') as zip: \n",
        "    print('Extracting all files...') \n",
        "    zip.extractall('resources/') # destinaci√≥n\n",
        "    print('Done!') "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting all files...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLDN-Fh_O7EN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "951e06ae-fed5-4880-b78b-339cf85ff3cb"
      },
      "source": [
        "%ls \"resources/ml-1m\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "movies.dat  ratings.dat  README  users.dat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T65mOBPdO8Qa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79b87b10-f904-4a74-ddba-61cbe5ad5337"
      },
      "source": [
        "# descargar MovieLens dataset\n",
        "url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'  \n",
        "urllib.request.urlretrieve(url, 'aclImdb_v1.tar.gz')\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('aclImdb_v1.tar.gz', <http.client.HTTPMessage at 0x7f1452c78eb8>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}